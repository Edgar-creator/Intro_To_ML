{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score,jaccard_score,make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Johns Hopkins University Ionosphere database\n",
      "\n",
      "2. Source Information:\n",
      "   -- Donor: Vince Sigillito (vgs@aplcen.apl.jhu.edu)\n",
      "   -- Date: 1989\n",
      "   -- Source: Space Physics Group\n",
      "              Applied Physics Laboratory\n",
      "              Johns Hopkins University\n",
      "              Johns Hopkins Road\n",
      "              Laurel, MD 20723\n",
      "\n",
      "3. Past Usage:\n",
      "   -- Sigillito, V. G., Wing, S. P., Hutton, L. V., \\& Baker, K. B. (1989).\n",
      "      Classification of radar returns from the ionosphere using neural\n",
      "      networks. Johns Hopkins APL Technical Digest, 10, 262-266.\n",
      "\n",
      "      They investigated using backprop and the perceptron training algorithm\n",
      "      on this database.  Using the first 200 instances for training, which\n",
      "      were carefully split almost 50% positive and 50% negative, they found\n",
      "      that a \"linear\" perceptron attained 90.7%, a \"non-linear\" perceptron\n",
      "      attained 92%, and backprop an average of over 96% accuracy on the\n",
      "      remaining 150 test instances, consisting of 123 \"good\" and only 24 \"bad\"\n",
      "      instances.  (There was a counting error or some mistake somewhere; there\n",
      "      are a total of 351 rather than 350 instances in this domain.) Accuracy\n",
      "      on \"good\" instances was much higher than for \"bad\" instances.  Backprop\n",
      "      was tested with several different numbers of hidden units (in [0,15])\n",
      "      and incremental results were also reported (corresponding to how well\n",
      "      the different variants of backprop did after a periodic number of\n",
      "      epochs).\n",
      "\n",
      "      David Aha (aha@ics.uci.edu) briefly investigated this database.\n",
      "      He found that nearest neighbor attains an accuracy of 92.1%, that\n",
      "      Ross Quinlan's C4 algorithm attains 94.0% (no windowing), and that\n",
      "      IB3 (Aha \\& Kibler, IJCAI-1989) attained 96.7% (parameter settings:\n",
      "      70% and 80% for acceptance and dropping respectively).\n",
      "\n",
      "4. Relevant Information:\n",
      "   This radar data was collected by a system in Goose Bay, Labrador.  This\n",
      "   system consists of a phased array of 16 high-frequency antennas with a\n",
      "   total transmitted power on the order of 6.4 kilowatts.  See the paper\n",
      "   for more details.  The targets were free electrons in the ionosphere.\n",
      "   \"Good\" radar returns are those showing evidence of some type of structure\n",
      "   in the ionosphere.  \"Bad\" returns are those that do not; their signals pass\n",
      "   through the ionosphere.\n",
      "\n",
      "   Received signals were processed using an autocorrelation function whose\n",
      "   arguments are the time of a pulse and the pulse number.  There were 17\n",
      "   pulse numbers for the Goose Bay system.  Instances in this databse are\n",
      "   described by 2 attributes per pulse number, corresponding to the complex\n",
      "   values returned by the function resulting from the complex electromagnetic\n",
      "   signal.\n",
      "\n",
      "5. Number of Instances: 351\n",
      "\n",
      "6. Number of Attributes: 34 plus the class attribute\n",
      "   -- All 34 predictor attributes are continuous\n",
      "\n",
      "7. Attribute Information:\n",
      "   -- All 34 are continuous, as described above\n",
      "   -- The 35th attribute is either \"good\" or \"bad\" according to the definition\n",
      "      summarized above.  This is a binary classification task.\n",
      "\n",
      "8. Missing Values: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"ionosphere_names.txt\") as text:\n",
    "    for line in text:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data preprocessing and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the \"ionosphere.csv\" dataset\n",
    "2. Clean the dataset, remove N/A s, uninformative columns if any\n",
    "3. Construct and plot inter feature correlation matrice\n",
    "4. Investigate distributions of each feature(make histogram plots), decide if the dataset needs normalization or not, if yes normalize it\n",
    "5. Last column is the target column which we will predict. Map (b, g) -> (0, 1)\n",
    "6. Split the dataset to train/test with 80/20 ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.1 Load the \"ionosphere.csv\" dataset\n",
    "df=pd.read_csv(\"ionosphere.csv\",header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "19    False\n",
      "20    False\n",
      "21    False\n",
      "22    False\n",
      "23    False\n",
      "24    False\n",
      "25    False\n",
      "26    False\n",
      "27    False\n",
      "28    False\n",
      "29    False\n",
      "30    False\n",
      "31    False\n",
      "32    False\n",
      "33    False\n",
      "34    False\n",
      "dtype: bool\n",
      "\n",
      "Row 248 is duplicated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN3</th>\n",
       "      <th>COLUMN4</th>\n",
       "      <th>COLUMN5</th>\n",
       "      <th>COLUMN6</th>\n",
       "      <th>COLUMN7</th>\n",
       "      <th>COLUMN8</th>\n",
       "      <th>COLUMN9</th>\n",
       "      <th>COLUMN10</th>\n",
       "      <th>COLUMN11</th>\n",
       "      <th>COLUMN12</th>\n",
       "      <th>...</th>\n",
       "      <th>COLUMN26</th>\n",
       "      <th>COLUMN27</th>\n",
       "      <th>COLUMN28</th>\n",
       "      <th>COLUMN29</th>\n",
       "      <th>COLUMN30</th>\n",
       "      <th>COLUMN31</th>\n",
       "      <th>COLUMN32</th>\n",
       "      <th>COLUMN33</th>\n",
       "      <th>COLUMN34</th>\n",
       "      <th>COLUMN35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>-0.20275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COLUMN3  COLUMN4  COLUMN5  COLUMN6  COLUMN7  COLUMN8  COLUMN9  COLUMN10  \\\n",
       "0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   0.03760   \n",
       "1  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000  -0.04549   \n",
       "2  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   0.01198   \n",
       "3  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   0.00000   \n",
       "4  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152  -0.16399   \n",
       "\n",
       "   COLUMN11  COLUMN12  ...  COLUMN26  COLUMN27  COLUMN28  COLUMN29  COLUMN30  \\\n",
       "0   0.85243  -0.17755  ...  -0.51171   0.41078  -0.46168   0.21266  -0.34090   \n",
       "1   0.50874  -0.67743  ...  -0.26569  -0.20468  -0.18401  -0.19040  -0.11593   \n",
       "2   0.73082   0.05346  ...  -0.40220   0.58984  -0.22145   0.43100  -0.17365   \n",
       "3   0.00000   0.00000  ...   0.90695   0.51613   1.00000   1.00000  -0.20099   \n",
       "4   0.52798  -0.20275  ...  -0.65158   0.13290  -0.53206   0.02431  -0.62197   \n",
       "\n",
       "   COLUMN31  COLUMN32  COLUMN33  COLUMN34  COLUMN35  \n",
       "0   0.42267  -0.54487   0.18641  -0.45300         1  \n",
       "1  -0.16626  -0.06288  -0.13738  -0.02447         0  \n",
       "2   0.60436  -0.24180   0.56045  -0.38238         1  \n",
       "3   0.25682   1.00000  -0.32382   1.00000         0  \n",
       "4  -0.05707  -0.59573  -0.04608  -0.65697         1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.2 Clean the dataset, remove N/A s, uninformative columns if any\n",
    "print(\"\\n\",df.isnull().sum()>0)\n",
    "\n",
    "print(\"\\nRow %s is duplicated\" % list(df[df.duplicated()==True].index)[0])\n",
    "df.drop(df[df.duplicated()==True].index,inplace=True)\n",
    "\n",
    "col=[]\n",
    "for i in range(1,df.shape[1]+1):\n",
    "    col.append(\"COLUMN\"+str(i))\n",
    "df.columns=col\n",
    "for i in df.columns[:-1]:\n",
    "    if len(df[i].value_counts())<=2:\n",
    "        df.drop(i,inplace=True,axis=1)\n",
    "#0.5 Last column is the target column which we will predict. Map (b, g) -> (0, 1)        \n",
    "df=df.replace(to_replace=\"g\",value=1)\n",
    "df=df.replace(to_replace=\"b\",value=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN3     0.516765\n",
      "COLUMN5     0.514353\n",
      "COLUMN7     0.448103\n",
      "COLUMN35    1.000000\n",
      "Name: COLUMN35, dtype: float64\n",
      "\n",
      "Correlation between COLUMN3 and COLUMN35: 0.5167654488294972\n",
      "Correlation between COLUMN4 and COLUMN35: 0.1258232928837144\n",
      "Correlation between COLUMN5 and COLUMN35: 0.5143532562365137\n",
      "Correlation between COLUMN6 and COLUMN35: 0.14852993676752776\n",
      "Correlation between COLUMN7 and COLUMN35: 0.4481029966142785\n",
      "Correlation between COLUMN8 and COLUMN35: 0.20721283881862262\n",
      "Correlation between COLUMN9 and COLUMN35: 0.2921648354659896\n",
      "Correlation between COLUMN10 and COLUMN35: 0.1195298511859076\n",
      "Correlation between COLUMN11 and COLUMN35: 0.16526743364518318\n",
      "Correlation between COLUMN12 and COLUMN35: 0.15917105186743682\n",
      "Correlation between COLUMN13 and COLUMN35: 0.17978453423808685\n",
      "Correlation between COLUMN14 and COLUMN35: 0.19683191720571508\n",
      "Correlation between COLUMN15 and COLUMN35: 0.2057926917482188\n",
      "Correlation between COLUMN16 and COLUMN35: 0.14856611469890477\n",
      "Correlation between COLUMN17 and COLUMN35: 0.08496021580256712\n",
      "Correlation between COLUMN18 and COLUMN35: 0.11967945836732839\n",
      "Correlation between COLUMN19 and COLUMN35: 0.11559085984229575\n",
      "Correlation between COLUMN20 and COLUMN35: 0.0358889197968059\n",
      "Correlation between COLUMN21 and COLUMN35: 0.21812407182758456\n",
      "Correlation between COLUMN22 and COLUMN35: -0.11674422726421582\n",
      "Correlation between COLUMN23 and COLUMN35: 0.2026876314970251\n",
      "Correlation between COLUMN24 and COLUMN35: 0.0066263581674241845\n",
      "Correlation between COLUMN25 and COLUMN35: 0.18616652651601553\n",
      "Correlation between COLUMN26 and COLUMN35: 0.0020819516644369927\n",
      "Correlation between COLUMN27 and COLUMN35: -0.10811009564524492\n",
      "Correlation between COLUMN28 and COLUMN35: 0.03653107756293354\n",
      "Correlation between COLUMN29 and COLUMN35: 0.24831115283928532\n",
      "Correlation between COLUMN30 and COLUMN35: -0.0037411142734865488\n",
      "Correlation between COLUMN31 and COLUMN35: 0.29296636474758253\n",
      "Correlation between COLUMN32 and COLUMN35: -0.03606780351017486\n",
      "Correlation between COLUMN33 and COLUMN35: 0.25942977598508205\n",
      "Correlation between COLUMN34 and COLUMN35: -0.06445094868814054\n"
     ]
    }
   ],
   "source": [
    "#0.3 Construct and plot inter feature correlation matrice\n",
    "print(abs(df.corr()[\"COLUMN35\"])[df.corr()[\"COLUMN35\"]>0.3])\n",
    "print()\n",
    "for j in df.columns[:-1]:\n",
    "    print(\"Correlation between %s and %s: %s\" % (j,df.columns[-1],df[[j,df.columns[-1]]].corr().iloc[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN3</th>\n",
       "      <th>COLUMN4</th>\n",
       "      <th>COLUMN5</th>\n",
       "      <th>COLUMN6</th>\n",
       "      <th>COLUMN7</th>\n",
       "      <th>COLUMN8</th>\n",
       "      <th>COLUMN9</th>\n",
       "      <th>COLUMN10</th>\n",
       "      <th>COLUMN11</th>\n",
       "      <th>COLUMN12</th>\n",
       "      <th>...</th>\n",
       "      <th>COLUMN26</th>\n",
       "      <th>COLUMN27</th>\n",
       "      <th>COLUMN28</th>\n",
       "      <th>COLUMN29</th>\n",
       "      <th>COLUMN30</th>\n",
       "      <th>COLUMN31</th>\n",
       "      <th>COLUMN32</th>\n",
       "      <th>COLUMN33</th>\n",
       "      <th>COLUMN34</th>\n",
       "      <th>COLUMN35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.643174</td>\n",
       "      <td>0.044499</td>\n",
       "      <td>0.602785</td>\n",
       "      <td>0.116220</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>0.119701</td>\n",
       "      <td>0.513311</td>\n",
       "      <td>0.181864</td>\n",
       "      <td>0.477543</td>\n",
       "      <td>0.155483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071390</td>\n",
       "      <td>0.540331</td>\n",
       "      <td>-0.066879</td>\n",
       "      <td>0.379526</td>\n",
       "      <td>-0.027987</td>\n",
       "      <td>0.353521</td>\n",
       "      <td>-0.003805</td>\n",
       "      <td>0.350362</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.497234</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.461428</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>0.521456</td>\n",
       "      <td>0.507050</td>\n",
       "      <td>0.484446</td>\n",
       "      <td>0.563725</td>\n",
       "      <td>0.495456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509208</td>\n",
       "      <td>0.516359</td>\n",
       "      <td>0.548550</td>\n",
       "      <td>0.576353</td>\n",
       "      <td>0.508699</td>\n",
       "      <td>0.571989</td>\n",
       "      <td>0.514310</td>\n",
       "      <td>0.523076</td>\n",
       "      <td>0.469007</td>\n",
       "      <td>0.479843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.473447</td>\n",
       "      <td>-0.065388</td>\n",
       "      <td>0.415473</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>0.219745</td>\n",
       "      <td>-0.055235</td>\n",
       "      <td>0.093298</td>\n",
       "      <td>-0.049003</td>\n",
       "      <td>0.027873</td>\n",
       "      <td>-0.065677</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332860</td>\n",
       "      <td>0.283612</td>\n",
       "      <td>-0.428992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.237083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.166810</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.873445</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.811145</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>0.729315</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.686450</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>0.670560</td>\n",
       "      <td>0.029750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015200</td>\n",
       "      <td>0.703345</td>\n",
       "      <td>-0.017685</td>\n",
       "      <td>0.499215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.335318</td>\n",
       "      <td>0.970445</td>\n",
       "      <td>0.451572</td>\n",
       "      <td>0.954185</td>\n",
       "      <td>0.536192</td>\n",
       "      <td>0.958157</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>0.154862</td>\n",
       "      <td>0.884572</td>\n",
       "      <td>0.154218</td>\n",
       "      <td>0.859490</td>\n",
       "      <td>0.200935</td>\n",
       "      <td>0.816777</td>\n",
       "      <td>0.172105</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          COLUMN3     COLUMN4     COLUMN5     COLUMN6     COLUMN7     COLUMN8  \\\n",
       "count  350.000000  350.000000  350.000000  350.000000  350.000000  350.000000   \n",
       "mean     0.643174    0.044499    0.602785    0.116220    0.551667    0.119701   \n",
       "std      0.497234    0.442060    0.519608    0.461428    0.492477    0.521456   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.473447   -0.065388    0.415473   -0.024868    0.219745   -0.055235   \n",
       "50%      0.873445    0.016700    0.811145    0.022930    0.729315    0.015085   \n",
       "75%      1.000000    0.194727    1.000000    0.335318    0.970445    0.451572   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          COLUMN9    COLUMN10    COLUMN11    COLUMN12  ...    COLUMN26  \\\n",
       "count  350.000000  350.000000  350.000000  350.000000  ...  350.000000   \n",
       "mean     0.513311    0.181864    0.477543    0.155483  ...   -0.071390   \n",
       "std      0.507050    0.484446    0.563725    0.495456  ...    0.509208   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%      0.093298   -0.049003    0.027873   -0.065677  ...   -0.332860   \n",
       "50%      0.686450    0.020665    0.670560    0.029750  ...   -0.015200   \n",
       "75%      0.954185    0.536192    0.958157    0.483613  ...    0.157922   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "         COLUMN27    COLUMN28    COLUMN29    COLUMN30    COLUMN31    COLUMN32  \\\n",
       "count  350.000000  350.000000  350.000000  350.000000  350.000000  350.000000   \n",
       "mean     0.540331   -0.066879    0.379526   -0.027987    0.353521   -0.003805   \n",
       "std      0.516359    0.548550    0.576353    0.508699    0.571989    0.514310   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.283612   -0.428992    0.000000   -0.237083    0.000000   -0.242993   \n",
       "50%      0.703345   -0.017685    0.499215    0.000000    0.446875    0.000000   \n",
       "75%      0.999523    0.154862    0.884572    0.154218    0.859490    0.200935   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         COLUMN33    COLUMN34    COLUMN35  \n",
       "count  350.000000  350.000000  350.000000  \n",
       "mean     0.350362    0.014521    0.642857  \n",
       "std      0.523076    0.469007    0.479843  \n",
       "min     -1.000000   -1.000000    0.000000  \n",
       "25%      0.000000   -0.166810    0.000000  \n",
       "50%      0.413115    0.000000    1.000000  \n",
       "75%      0.816777    0.172105    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.4 Investigate distributions of each feature(make histogram plots), decide if the dataset needs normalization or not, if yes normalize it\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((280, 32), (70, 32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.6 Split the dataset to train/test with 80/20 ratio\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "xtrain , xtest, ytrain, ytest =tts(df[df.columns.difference([\"COLUMN35\"])],df[\"COLUMN35\"],test_size=0.2,random_state=12)\n",
    "xtrain.shape ,xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression of sklearn, run a grid search on parameter C from the values [0.01, 0.1, 1., 10, 100]. Select the best model by running 5 Fold cross validation on train set according to f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8045977  0.875      0.82352941 0.86419753 0.85714286]\n",
      "\n",
      "For C = 0.01 the F1_Score(mean of 5 Fold cross validation) is 0.8448935001842373 \n",
      "[0.85365854 0.92105263 0.87179487 0.8974359  0.92307692]\n",
      "\n",
      "For C = 0.1 the F1_Score(mean of 5 Fold cross validation) is 0.893403772094401 \n",
      "[0.90909091 0.88888889 0.88311688 0.88311688 0.93506494]\n",
      "\n",
      "For C = 1.0 the F1_Score(mean of 5 Fold cross validation) is 0.8998556998556999 \n",
      "[0.88311688 0.84507042 0.85714286 0.89189189 0.94594595]\n",
      "\n",
      "For C = 10 the F1_Score(mean of 5 Fold cross validation) is 0.8846336001265579 \n",
      "[0.88311688 0.84507042 0.86842105 0.88888889 0.93150685]\n",
      "\n",
      "For C = 100 the F1_Score(mean of 5 Fold cross validation) is 0.8834008192975261 \n",
      "\n",
      "The best model is with C = 1.0 \n"
     ]
    }
   ],
   "source": [
    "c=  [0.01, 0.1, 1., 10, 100]\n",
    "max1=0\n",
    "for i in c:\n",
    "    log  = LogisticRegression(C=i,solver='liblinear')\n",
    "    pred = cross_val_score(log,xtrain,ytrain,scoring=make_scorer(f1_score),cv=5,)\n",
    "    print(pred)\n",
    "    print(\"\\nFor C = %s the F1_Score(mean of 5 Fold cross validation) is %s \"%(i,pred.mean()))\n",
    "    if pred.mean()>max1:\n",
    "        max1=pred.mean()\n",
    "        k=i\n",
    "        \n",
    "print(\"\\nThe best model is with C = %s \" %k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimensionality Reduction PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Project data to dimension $K_1$ so that total explained variance ratio is $\\geq$0.9\n",
    "2. Project data to dimension $K_2$ so that total explained variance ratio is $\\geq$0.99\n",
    "3. Train Logistic Regression with the best C from task $\\bf 1$ on projected data that you got in $\\bf 2.1$ and $\\bf 2.2$\n",
    "4. Compare Jaccard Index and F1 score of the three models.\n",
    "5. Investigate the learned coefficients of best model that you found in $\\bf 1$, make two training sets by selecting $K_1$, $K_2$ most important features.\n",
    "6. Train Logistic Regression with the best C from task $\\bf 1$ on datasets that you made in $\\bf 2.5$, and compare Jaccard Index and F1 score with respective models from $\\bf 2.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36071873 0.13563987 0.09037006 0.07778065 0.06364355 0.05449194\n",
      " 0.0362001  0.02733667 0.0267972  0.02179032 0.01699805 0.0154841\n",
      " 0.01390241 0.01037287 0.0091721  0.00678083 0.00588009 0.00565324]\n",
      "\n",
      "The explained_variance_ratio is 0.9086391154782942 and the n_components = 18\n",
      "\n",
      "\n",
      " [0.36071873 0.13563987 0.09037006 0.07778065 0.06364355 0.05449194\n",
      " 0.0362001  0.02733667 0.0267972  0.02179032 0.01699805 0.0154841\n",
      " 0.01390241 0.01037287 0.0091721  0.00678083 0.00588009 0.00565324\n",
      " 0.00388952 0.00329393 0.00299355 0.0027775  0.00199279 0.00140145\n",
      " 0.00120278 0.0008624  0.0006401  0.00054728 0.0005362 ]\n",
      "\n",
      "The explained_variance_ratio is 0.990609059805197 and the n_components = 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(280,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.1 Project data to dimension  ùêæ1  so that total explained variance ratio is  ‚â• 0.9\n",
    "#2.2 Project data to dimension  ùêæ2  so that total explained variance ratio is  ‚â• 0.99\n",
    "\n",
    "#pca1 = PCA(n_components=0.9)\n",
    "#K1= pca1(xtrain)\n",
    "#K1_test= pca1(xtest)\n",
    "for i in range (1,xtrain.shape[1]+1):\n",
    "    pca1 = PCA(n_components=i)#'auto', 'full', 'arpack', 'randomized'\n",
    "    K1 = pca1.fit_transform(xtrain)\n",
    "    sum1 = pca1.explained_variance_ratio_.sum()\n",
    "    if sum1>=0.90:\n",
    "        K1_test=pca1.fit_transform(xtest)\n",
    "        print(pca1.explained_variance_ratio_)\n",
    "        print(\"\\nThe explained_variance_ratio is %s and the n_components = %s\" % (sum1,i))\n",
    "        break\n",
    "\n",
    "#pca1 = PCA(n_components=0.9)\n",
    "#K2= pca2(xtrain) \n",
    "##K2_test= pca2(xtest)\n",
    "for i in range (1,xtrain.shape[1]+1):\n",
    "    pca2 = PCA(n_components=i)\n",
    "    K2 = pca2.fit_transform(xtrain)\n",
    "    sum1 = pca2.explained_variance_ratio_.sum()\n",
    "    if sum1>=0.99:\n",
    "        K2_test=pca2.fit_transform(xtest)\n",
    "        \n",
    "        print(\"\\n\\n\",pca2.explained_variance_ratio_)\n",
    "        print(\"\\nThe explained_variance_ratio is %s and the n_components = %s\" % (sum1,i))\n",
    "        break\n",
    "K1_test.shape,K2_test.shape\n",
    "\n",
    "from scipy.linalg import svd\n",
    "cov = xtrain.dot(xtrain.T)/(xtrain.shape[1]-1)\n",
    "u,s,v = svd(cov)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first model f1_score = 0.86  and jaccard_score = 0.754 \n",
      "\n",
      "For the Second model(K1) f1_score = 0.714  and jaccard_score = 0.556 \n",
      "\n",
      "For the Third model(K2) f1_score = 0.713  and jaccard_score = 0.554 \n"
     ]
    }
   ],
   "source": [
    "#2.3 Train Logistic Regression with the best C from task  1  on projected data that you got in  2.1  and  2.2\n",
    "#2.4 Compare Jaccard Index and F1 score of the three models.\n",
    "log = LogisticRegression(C=k,solver='liblinear')\n",
    "log.fit(xtrain,ytrain)\n",
    "pred = log.predict(xtest)\n",
    "print(\"For the first model f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,pred),3),round(jaccard_score(ytest,pred),3))\n",
    ")\n",
    "\n",
    "log1 = LogisticRegression(C=k,solver='liblinear')\n",
    "log1.fit(K1,ytrain)\n",
    "K1_log = log1.predict(K1_test)\n",
    "print(\"\\nFor the Second model(K1) f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K1_log),3),round(jaccard_score(ytest,K1_log),3)))\n",
    "\n",
    "log2 = LogisticRegression(C=k,solver='liblinear')\n",
    "log2.fit(K2,ytrain)\n",
    "K2_log = log2.predict(K2_test)\n",
    "print(\"\\nFor the Third model(K2) f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K2_log),3),round(jaccard_score(ytest,K2_log),3))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The most unimportant feature after Logistic Regression is COLUMN3 with weight -0.0329\n",
      "\n",
      "The most important feature after Logistic Regression is COLUMN15 with weight -1.9262\n",
      "\n",
      "The importance of features and their absolute value \n",
      "\n",
      "[('COLUMN15', 1.9262), ('COLUMN20', 1.6303), ('COLUMN23', 1.6248), ('COLUMN30', 1.5124), ('COLUMN28', 1.3084), ('COLUMN11', 1.1995), ('COLUMN34', 1.1005), ('COLUMN33', 1.0701), ('COLUMN4', 0.8986), ('COLUMN7', 0.8791), ('COLUMN31', 0.8467), ('COLUMN16', 0.7756), ('COLUMN22', 0.7425), ('COLUMN21', 0.7035), ('COLUMN29', 0.6636), ('COLUMN14', 0.6314), ('COLUMN17', 0.6242), ('COLUMN19', 0.6157), ('COLUMN25', 0.5977), ('COLUMN24', 0.5875), ('COLUMN32', 0.4433), ('COLUMN5', 0.3917), ('COLUMN27', 0.3601), ('COLUMN9', 0.3595), ('COLUMN12', 0.3305), ('COLUMN18', 0.304), ('COLUMN6', 0.3023), ('COLUMN13', 0.3002), ('COLUMN8', 0.2611), ('COLUMN10', 0.2592), ('COLUMN26', 0.0429), ('COLUMN3', 0.0329)]\n"
     ]
    }
   ],
   "source": [
    "#2.5 Investigate the learned coefficients of best model that you found in 1 ,make two training sets by selecting  ùêæ1 ,ùêæ2  most important features.\n",
    "d ={}\n",
    "for i,j in zip(df,log.coef_[0]):\n",
    "    d[i] = abs(round(j,4))  \n",
    "d= sorted(d.items(),key=lambda x:x[1],reverse=True)\n",
    "\n",
    "\n",
    "for i,j in zip(df,log.coef_[0]):\n",
    "    if abs(j) == max(abs(log.coef_[0])):\n",
    "        print(\"\\nThe most important feature after Logistic Regression is %s with weight %s\" % (i,round(j,4)))\n",
    "    elif abs(j) == min(abs(log.coef_[0])):\n",
    "        print(\"\\nThe most unimportant feature after Logistic Regression is %s with weight %s\" % (i,round(j,4)))    \n",
    "print(\"\\nThe importance of features and their absolute value \\n\\n%s\" %d)\n",
    "\n",
    "\n",
    "def select_most_imp_features(v,df,lk,test=False):\n",
    "    d={}\n",
    "    \"\"\"v: The firs most important k features\n",
    "       df: data(numpy.ndarray)\n",
    "       lk: The list of explained_variance_ratio or coefficents\"\"\"\n",
    "    for i,j in zip(list(range(df.shape[0])),lk):\n",
    "        d[i] = abs(round(j,6))\n",
    "    a=sorted(d.items(),key=lambda x:x[1],reverse=True)\n",
    "    b = [i[0] for i in a]\n",
    "    new_data = df[:,b[:v]]\n",
    "    if test is False: \n",
    "        return new_data\n",
    "    else:\n",
    "        return b[:v]\n",
    "        \n",
    "\n",
    "K1_selected = select_most_imp_features(12,K1,pca1.explained_variance_ratio_)\n",
    "K2_selected = select_most_imp_features(18,K2,pca2.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the First model with  firs 12 important features f1_score = 0.74227  and jaccard_score = 0.59016 \n",
      "\n",
      "For the model(K1) f1_score = 0.714  and jaccard_score = 0.556 \n",
      "\n",
      "\n",
      "\n",
      "For the Second model with  firs 18 important features f1_score = 0.71429  and jaccard_score = 0.55556 \n",
      "\n",
      "For the  model(K2) f1_score = 0.713  and jaccard_score = 0.554 \n"
     ]
    }
   ],
   "source": [
    "#2.6 Train Logistic Regression with the best C from task  1  on datasets that you made in  2.5 , and compare Jaccard Index and F1 score with respective models from  2.3\n",
    "K1_selected_test = K1_test[:,select_most_imp_features(12,K1_test,pca1.explained_variance_ratio_,test=True)]\n",
    "\n",
    "log_selected1 = LogisticRegression(C=k,solver='liblinear')\n",
    "log_selected1.fit(K1_selected,ytrain)\n",
    "K1_selected_pred = log_selected1.predict(K1_selected_test)\n",
    "print(\"\\nFor the First model with  firs 12 important features f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K1_selected_pred),5),round(jaccard_score(ytest,K1_selected_pred),5)))\n",
    "\n",
    "print(\"\\nFor the model(K1) f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K1_log),3),round(jaccard_score(ytest,K1_log),3)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "K2_selected_test = K2_test[:,select_most_imp_features(18,K2_test,pca2.explained_variance_ratio_,test=True)]\n",
    "log_selected2 = LogisticRegression(C=k,solver='liblinear')\n",
    "log_selected2.fit(K2_selected,ytrain)\n",
    "K2_selected_pred = log_selected2.predict(K2_selected_test)\n",
    "print(\"\\n\\n\\nFor the Second model with  firs 18 important features f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K2_selected_pred),5),round(jaccard_score(ytest,K2_selected_pred),5)))\n",
    "\n",
    "print(\"\\nFor the  model(K2) f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K2_log),3),round(jaccard_score(ytest,K2_log),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimensionality Reduction LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Project data to dimension $K_1$ so that total explained variance ratio is $\\geq$0.9\n",
    "2. Project data to dimension $K_2$ so that total explained variance ratio is $\\geq$0.99\n",
    "3. Train Logistic Regression with the best C from task $\\bf 1$ on projected data that you got in $\\bf 3.1$ and $\\bf 3.2$\n",
    "4. Compare Jaccard Index and F1 score with the previous models in tasks $\\bf 1$ and $\\bf 2$.\n",
    "5. Investigate the learned coefficients of best model that you found in $\\bf 1$, make two training sets by selecting $K_1$, $K_2$ most important features.\n",
    "6. Train Logistic Regression with the best C from task $\\bf 1$ on datasets that you made in $\\bf 3.5$, and compare Jaccard Index and F1 score with respective models from $\\bf 3.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "For the LDA model  f1_score = 0.97959  and jaccard_score = 0.96 \n"
     ]
    }
   ],
   "source": [
    "#3.1,3.2 Project data to dimension  ùêæ1  so that total explained variance ratio is  ‚â• 0.9\n",
    "lda = LDA(n_components=1)\n",
    "K1 = lda.fit_transform(xtrain,ytrain)\n",
    "K1_test3 = lda.fit_transform(xtest,ytest)\n",
    "log = LogisticRegression(C=k,solver=\"liblinear\")\n",
    "log.fit(K1,ytrain)\n",
    "K1_pred3 = log.predict(K1_test3)\n",
    "print(\"\\n\\n\\nFor the LDA model  f1_score = %s  and jaccard_score = %s \" % (round(f1_score(ytest,K1_pred3),5),round(jaccard_score(ytest,K1_pred3),5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 2D plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 4 plots\n",
    "1. Select 2 most important features of the best Logistic Regression model from task $\\bf 1$. Make scatter plot using these two features, and color according to target variable.\n",
    "2. Select first two principal components from task $\\bf 2.2$.Make scatter plot using these two components, and color according to target variable.\n",
    "3. Select first two linear discriminant components from task $\\bf 3.2$.Make scatter plot using these two components, and color according to target variable.\n",
    "4. Project data to 2D space and plot it, again by coloring according to target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('COLUMN15', 1.9262), ('COLUMN20', 1.6303)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(d[:2])#2 most important features of the best Logistic Regression model from task  1\n",
    "plt.xlabel('COLUMN15')\n",
    "plt.ylabel('COLUMN20')\n",
    "plt.scatter(df['COLUMN15'].loc[list(ytrain[ytrain==1].index)],df['COLUMN25'].loc[list(ytrain[ytrain==1].index)],c=\"c\")\n",
    "plt.scatter(df['COLUMN15'].loc[list(ytrain[ytrain==0].index)],df['COLUMN25'].loc[list(ytrain[ytrain==0].index)],color=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4.2 Select first two principal components from task  2.2 .Make scatter plot using these two components, and color according to target variable.\n",
    "l=select_most_imp_features(2,K2,pca2.explained_variance_ratio_,test=True)\n",
    "print(l)#2 most important features of the best Logistic Regression model from task  2.2(for K2 or K1)\n",
    "plt.xlabel('0')\n",
    "plt.ylabel('1')\n",
    "plt.scatter(K2[:,0][np.where(np.array(ytrain)==0)],K2[:,1][np.where(np.array(ytrain)==0)],c=\"c\")\n",
    "plt.scatter(K2[:,0][np.where(np.array(ytrain)==1)],K2[:,1][np.where(np.array(ytrain)==1)],color=\"k\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x9af5f30>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "D2 = pca.fit_transform(df)\n",
    "plt.scatter(D2[:,0][np.where(np.array(ytrain)==0)],D2[:,1][np.where(np.array(ytrain)==0)],c=\"c\")\n",
    "plt.scatter(D2[:,0][np.where(np.array(ytrain)==1)],D2[:,1][np.where(np.array(ytrain)==1)],color=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
