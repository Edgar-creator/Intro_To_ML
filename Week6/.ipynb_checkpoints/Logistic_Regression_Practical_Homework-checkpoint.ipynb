{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset \n",
    "load diabetes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "0     0.639530  0.847771       0.149543       0.906679 -0.692439  0.203880   \n",
      "1    -0.844335 -1.122665      -0.160441       0.530556 -0.692439 -0.683976   \n",
      "2     1.233077  1.942458      -0.263769      -1.287373 -0.692439 -1.102537   \n",
      "3    -0.844335 -0.997558      -0.160441       0.154433  0.123221 -0.493721   \n",
      "4    -1.141108  0.503727      -1.503707       0.906679  0.765337  1.408828   \n",
      "\n",
      "   DiabetesPedigreeFunction       Age  Outcome  \n",
      "0                  0.468187  1.425067        1  \n",
      "1                 -0.364823 -0.190548        0  \n",
      "2                  0.604004 -0.105515        1  \n",
      "3                 -0.920163 -1.040871        0  \n",
      "4                  5.481337 -0.020483        1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.847771</td>\n",
       "      <td>0.149543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.122665</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.942458</td>\n",
       "      <td>-0.263769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.997558</td>\n",
       "      <td>-0.160441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.503727</td>\n",
       "      <td>-1.503707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Glucose  BloodPressure  Outcome\n",
       "0  0.847771       0.149543        1\n",
       "1 -1.122665      -0.160441        0\n",
       "2  1.942458      -0.263769        1\n",
       "3 -0.997558      -0.160441        0\n",
       "4  0.503727      -1.503707        1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes_data.csv\")\n",
    "\n",
    "for i in df.columns[:-1]:\n",
    "    df[i]=(df[i]-df[i].mean())/df[i].std()\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df1 = df[['Glucose','BloodPressure','Outcome']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "xtrain,xtest,ytrain,ytest= tts(df1[df1.columns.difference([\"Outcome\"])],df1['Outcome'],test_size=0.25,random_state=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the following functions to create your own logistic regression algorithm from scratch.\n",
    "#### Feel free to use more additinal functions in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BloodPressure    0.459976\n",
      "Glucose          0.245517\n",
      "for_intercept    0.731059\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "    \"\"\"\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    \n",
    "    \"\"\"\n",
    "print(sigmoid(xtrain.loc[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08974456839456572"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic_func(beta,X):\n",
    "    return 1/(1+np.exp(np.dot(np.array(beta),-X.T)))\n",
    "    \n",
    "    \"\"\"\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    :param beta: value of beta (1 dimensional np.array)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "logistic_func([1,1], xtrain.iloc[458])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85.30688105 -3.01070905]\n"
     ]
    }
   ],
   "source": [
    "def gradient(beta, X, Y):\n",
    "    return np.dot((logistic_func(beta,X) -Y).T,X)\n",
    "    \n",
    "    \"\"\"\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    :param Y: response variables (1 dimensional np.array)\n",
    "    :param beta: value of beta (1 dimensional np.array)\n",
    "    :return: np.array i.e. gradient according to the data\n",
    "    \n",
    "    \"\"\"\n",
    "print(gradient(np.array([1,1]),xtrain,ytrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166089091145063"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost_func(X, Y, beta):\n",
    "    cost=0\n",
    "    for i in range(X.shape[0]):\n",
    "        cost+=-Y.iloc[i]*np.log(logistic_func(X.iloc[i],beta))-(1-Y.iloc[i])*np.log(1-logistic_func(X.iloc[i],beta))\n",
    "    return cost/X.shape[0]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    :param Y: response variables (1 dimensional np.array)\n",
    "    :param beta: value of beta (1 dimensional np.array)\n",
    "    :return: numberic value of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "cost_func(xtrain,ytrain,np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01090786,  1.09821521])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def gradient_descent(X, Y, epsilon=1e-6, step_size=1e-4, max_steps=600):\n",
    "    n=X.shape[0]\n",
    "    m=X.shape[1]\n",
    "    beta=np.zeros(m)\n",
    "    ls=[cost_func(X, Y, beta)]\n",
    "    for i in range(max_steps):\n",
    "        beta = beta - step_size*gradient(beta, X, Y)\n",
    "        #ls.append(cost_func(X, Y, beta))\n",
    "        #if ls[-2]-ls[-1]<epsilon:\n",
    "           # break\n",
    "    return beta\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    :param Y: response variables (1 dimensional np.array)\n",
    "    :param epsilon: threshold for a change in cost function value\n",
    "    :param max_steps: maximum number of iterations before algorithm will\n",
    "        terminate.\n",
    "    :return: value of beta (1 dimensional np.array)\n",
    "    \n",
    "    \"\"\"\n",
    "gradient_descent(xtrain, ytrain, epsilon=1e-6, step_size=1e-4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic_func(beta,xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run logistic regression using the features of your choice and using \"Outcome\" as a target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1\n",
      " 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "370    1\n",
       "388    1\n",
       "611    1\n",
       "550    0\n",
       "232    0\n",
       "      ..\n",
       "486    0\n",
       "598    1\n",
       "118    0\n",
       "143    1\n",
       "199    1\n",
       "Name: Outcome, Length: 192, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta=gradient_descent(xtrain, ytrain, epsilon=1e-6, step_size=1e-4)\n",
    "print(np.where(logistic_func(beta,xtest)>0.5,1,0))\n",
    "ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the logistic regression available in Sklearn on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 [[-0.01188779  1.09367375]]\n",
      "[[84 35]\n",
      " [18 55]]\n",
      "Accuracy is 0.65566\n",
      "Precision is 0.61111\n",
      "Recall is 0.75342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear',fit_intercept=False)\n",
    "logreg.fit(xtrain,ytrain)\n",
    "pred = logreg.predict(xtest)\n",
    "print(logreg.intercept_,logreg.coef_)\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn import metrics\n",
    "cm = cm(ytest,pred)\n",
    "print(cm)\n",
    "print(\"Accuracy is %s\" % round((cm[1][1]+cm[0][0])/(cm[1][1]+cm[0][0]+cm[1][0]+cm[1][1]),5))\n",
    "print(\"Precision is %s\" % round(cm[1][1]/(cm[1][1]+cm[0][1]),5))\n",
    "print(\"Recall is %s\" % round(cm[1][1]/(cm[1][1]+cm[1][0]),5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: try to plot the results of your algorithm i.e. a scatter plot of points classified into 2 classes in different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-77cd57a73d57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1601\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4442\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4444\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , axis = plt.subplots(2,1,figsize=(12,12))\n",
    "axis[0].scatter(xtest.iloc[np.where(pred==0)],pred[pred==0])\n",
    "axis[0].scatter(xtest.iloc[np.where(pred==1)],pred[pred==1],color=\"r\")\n",
    "\n",
    "\n",
    "axis[1].scatter(xtest.iloc[np.where(ytest==0)],ytest[ytest==0])\n",
    "axis[1].scatter(xtest.iloc[np.where(ytest==1)],ytest[ytest==1],color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
