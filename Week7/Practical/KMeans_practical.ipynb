{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load and process dataset\n",
    "load breast_cancer.csv, drop columns \"id\" and \"Unnamed: 32\", investigate the dataset, and divide into train and test with 80/20 ratio, map values of \"diagnosis\" from (\"B\",\"M\") to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"breast_cancer.csv\")\n",
    "df1=df.drop([\"id\",\"Unnamed: 32\"],axis=1)\n",
    "df1=df1.replace(to_replace=\"M\",value=1)\n",
    "df1=df1.replace(to_replace=\"B\",value=0)\n",
    "print(df1.isnull().sum())\n",
    "print(df1.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between radius_mean and target column: 0.7300285113754569\n",
      "Correlation between texture_mean and target column: 0.4151852998452046\n",
      "Correlation between perimeter_mean and target column: 0.742635529725833\n",
      "Correlation between area_mean and target column: 0.7089838365853909\n",
      "Correlation between smoothness_mean and target column: 0.3585599650859322\n",
      "Correlation between compactness_mean and target column: 0.5965336775082529\n",
      "Correlation between concavity_mean and target column: 0.6963597071719053\n",
      "Correlation between concave points_mean and target column: 0.7766138400204361\n",
      "Correlation between symmetry_mean and target column: 0.3304985542625467\n",
      "Correlation between fractal_dimension_mean and target column: -0.012837602698432364\n",
      "Correlation between radius_se and target column: 0.5671338208247176\n",
      "Correlation between texture_se and target column: -0.008303332973877434\n",
      "Correlation between perimeter_se and target column: 0.5561407034314833\n",
      "Correlation between area_se and target column: 0.5482359402780249\n",
      "Correlation between smoothness_se and target column: -0.06701601057948744\n",
      "Correlation between compactness_se and target column: 0.2929992442488583\n",
      "Correlation between concavity_se and target column: 0.2537297659808306\n",
      "Correlation between concave points_se and target column: 0.40804233271650514\n",
      "Correlation between symmetry_se and target column: -0.006521755870647959\n",
      "Correlation between fractal_dimension_se and target column: 0.0779724173902561\n",
      "Correlation between radius_worst and target column: 0.7764537785950388\n",
      "Correlation between texture_worst and target column: 0.4569028213967982\n",
      "Correlation between perimeter_worst and target column: 0.782914137173759\n",
      "Correlation between area_worst and target column: 0.7338250349210516\n",
      "Correlation between smoothness_worst and target column: 0.4214648610664031\n",
      "Correlation between compactness_worst and target column: 0.5909982378417925\n",
      "Correlation between concavity_worst and target column: 0.6596102103692344\n",
      "Correlation between concave points_worst and target column: 0.7935660171412696\n",
      "Correlation between symmetry_worst and target column: 0.41629431104861897\n",
      "Correlation between fractal_dimension_worst and target column: 0.3238721887208239\n"
     ]
    }
   ],
   "source": [
    "for i in df1.columns[1:]:\n",
    "    print(\"Correlation between %s and target column: %s\" % (i,df1[[i,df1.columns[0]]].corr().iloc[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                    0.372583\n",
       "radius_mean                 14.127292\n",
       "texture_mean                19.289649\n",
       "perimeter_mean              91.969033\n",
       "area_mean                  654.889104\n",
       "smoothness_mean              0.096360\n",
       "compactness_mean             0.104341\n",
       "concavity_mean               0.088799\n",
       "concave points_mean          0.048919\n",
       "symmetry_mean                0.181162\n",
       "fractal_dimension_mean       0.062798\n",
       "radius_se                    0.405172\n",
       "texture_se                   1.216853\n",
       "perimeter_se                 2.866059\n",
       "area_se                     40.337079\n",
       "smoothness_se                0.007041\n",
       "compactness_se               0.025478\n",
       "concavity_se                 0.031894\n",
       "concave points_se            0.011796\n",
       "symmetry_se                  0.020542\n",
       "fractal_dimension_se         0.003795\n",
       "radius_worst                16.269190\n",
       "texture_worst               25.677223\n",
       "perimeter_worst            107.261213\n",
       "area_worst                 880.583128\n",
       "smoothness_worst             0.132369\n",
       "compactness_worst            0.254265\n",
       "concavity_worst              0.272188\n",
       "concave points_worst         0.114606\n",
       "symmetry_worst               0.290076\n",
       "fractal_dimension_worst      0.083946\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = StandardScaler()\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train,X_test,Y_train,Y_test =tts(df1[df1.columns[1:]],df1[\"diagnosis\"],test_size=0.2,random_state=6)\n",
    "\n",
    "st.fit(X_train)\n",
    "xStandart_train = st.transform(X_train)\n",
    "xStandart_test = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    def __init__(self, K, metric='L2', max_iter=200, eps=1e-4):\n",
    "        self.K=K\n",
    "        self.max_iter=max_iter\n",
    "        self.eps=eps\n",
    "        self.cluster_centers=np.array([])\n",
    "        self.R=np.array([])\n",
    "        self.metric=metric\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        if metric is 'L2' let self.dist be a function that computes euclidian distance between x and y vectors,\n",
    "        if metric is 'L1' let self.dist be a function that computes manhattan distance between x and y vectors,\n",
    "        otherwise raise not implemented error\n",
    "        \"\"\"\n",
    "        if metric=='L2':\n",
    "            self.dist = lambda x,y: np.linalg.norm(x-y,2)\n",
    "        elif metric=='L1':\n",
    "            self.dist = lambda x,y: np.linalg.norm(x-y,1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def distortion(self, X, R):\n",
    "        \"\"\"\n",
    "        param X: numpy array of shape (M,N)\n",
    "        param r: numpy array of shape (M), shows to which cluster each row of X belongs\n",
    "        return: distortion value of the dataset\n",
    "        \"\"\"\n",
    "        #TODO calculate distortion measure using X and self.cluster_centers\n",
    "        sum_ = 0\n",
    "        for k in range(self.K):\n",
    "            mask = R[:, k] == 1\n",
    "            X_k = X[mask]\n",
    "            sum_ += np.sum(self.dist(X_k, self.centroids[k]))\n",
    "        \n",
    "        return sum_\n",
    "    \n",
    "        #raise NotImplementedError\n",
    "        \n",
    "    def init_centroids(self, X, centers_init):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        :param centers_init: numpy array of shape (K,N)\n",
    "        \"\"\"\n",
    "        \"\"\"TODO: \n",
    "        If centers_init is 'random' initialize self.cluster_centers with random K items from X,\n",
    "        if it is 'kmeans++' initialize centroids according to the algorithm in \n",
    "        http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf page 3,\n",
    "        otherwise raise not implemented error .\n",
    "        \"\"\"\n",
    "        if centers_init=='random':\n",
    "            self.cluster_centers = X[np.random.choice(X.shape[0],self.K, replace=False),:]  \n",
    "        elif centers_init=='kmeans++':\n",
    "            self.cluster_centers =  X[np.random.choice(X.shape[0],1, replace=False),:]\n",
    "            \n",
    "            for k in range(1,self.K):\n",
    "                D = []\n",
    "                for i in range(len(X)):\n",
    "                    D.append(min([self.dist(X[i],elem) for elem in self.cluster_centers]))\n",
    "\n",
    "                p=[]\n",
    "                for i in range(len(X)):\n",
    "                    p.append(D[i]/sum(D))\n",
    "\n",
    "                self.cluster_centers = np.vstack([self.cluster_centers, X[np.random.choice(X.shape[0],1,replace=False,p=p),:]])\n",
    "                \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def fit(self, X, centers_init='random'):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        :param centers_init: numpy array of shape (K,N)\n",
    "        \"\"\"\n",
    "        \"\"\"TODO: \n",
    "        1. Initialize cluster centers using self.init_centroids method\n",
    "        2. Implement KMeans algorithm and  terminate it when either self.max_iter iterations are performed,\n",
    "        or the biggest change in cluster centers is smaller than self.eps\n",
    "        \n",
    "        The final cluster centers should be saved in self.cluster_centers\n",
    "        \"\"\"\n",
    "        self.init_centroids(X, centers_init)\n",
    "        \n",
    "        R = np.zeros((len(X),self.K), dtype= int)\n",
    "        t=0\n",
    "        cluster_centers_prev = self.cluster_centers.copy()\n",
    "        max_change = 1000\n",
    "        while (t<self.max_iter) and max_change > self.eps:\n",
    "            \n",
    "            R = np.zeros((len(X),self.K), dtype= int)\n",
    "    \n",
    "            # updating R[i,k]\n",
    "            for i in range(len(X)):\n",
    "                k = np.argmin(np.array([self.dist(X[i],center) for center in self.cluster_centers]))\n",
    "                R[i,k]=1\n",
    "                \n",
    "            \n",
    "            # updating self.cluster_centers\n",
    "            for k in range(self.K):\n",
    "                mask = R[:, k] == 1\n",
    "                numerator = X[mask].sum(axis=0)\n",
    "                denominator = R[:, k].sum()\n",
    "                self.cluster_centers[k] = numerator / denominator\n",
    "                \n",
    "            max_change = (np.max([self.dist(cluster_centers_prev[s],self.cluster_centers[s]) for s in range(self.K)]))\n",
    "            cluster_centers_prev = self.cluster_centers.copy()\n",
    "            t+=1\n",
    "        #raise NotImplementedError\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of shape (M,N)\n",
    "        :return: numpy array of shape (M,)\n",
    "        \"\"\"\n",
    "        \"\"\"TODO:\n",
    "        using  self.cluster_centers predict to which cluster each datapoint of X belongs, values in returned array\n",
    "        are integers(id of the cluster). \n",
    "        \"\"\"\n",
    "        #fit(X, centers_init)\n",
    "        y_pred=[]\n",
    "        for i in range(len(X)):\n",
    "            k = np.argmin(np.array([self.dist(X[i],center) for center in self.cluster_centers]))\n",
    "            y_pred.append(k)\n",
    "                \n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the dataset with kmeans, model and predict malignancy of tumors in the test set entries\n",
    "## 1. Perform clustering using the following hyperparameter pairs\n",
    "1. metric='L1', center_init='random'\n",
    "2. metric='L1', center_init='kmeans++'\n",
    "3. metric='L2', center_init='random'\n",
    "4. metric='L2', center_init='kmeans++'\n",
    "\n",
    "## 2. Predict malignancy of tumors in the test set entries using all 4 models trained above, compare their performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KMeans(K=2, metric='L1')\n",
    "clf2 = KMeans(K=2, metric='L1')\n",
    "clf3 = KMeans(K=2, metric='L2')\n",
    "clf4 = KMeans(K=2, metric='L2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1\n",
      " 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 0 1]\n",
      "[ True  True False False  True False False  True False False False False\n",
      " False False  True  True False  True  True  True False False  True False\n",
      "  True False False False  True  True False False False  True False False\n",
      " False False False False  True False  True False False  True False  True\n",
      " False  True  True  True False False  True False  True  True False  True\n",
      "  True False False  True False  True False False False  True False  True\n",
      " False False  True  True False  True False  True False False False  True\n",
      " False False False  True False  True False  True False False  True False\n",
      "  True False False  True False False False False  True False False False\n",
      " False False  True  True  True False]\n",
      "ModeResult(mode=array([1], dtype=int64), count=array([44]))\n"
     ]
    }
   ],
   "source": [
    "clf1.fit(xStandart_train, centers_init='random')\n",
    "clusters = clf1.predict(xStandart_test)\n",
    "print(clusters)\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(2):\n",
    "    mask = (clusters == i)\n",
    "    print(mask)\n",
    "    \n",
    "    print(mode(Y_test[mask]))\n",
    "    break\n",
    " \n",
    "    \n",
    "\n",
    "#print(f'accuracy_score: ', accuracy_score(Y_test, labels))\n",
    "#print(f'accuracy_score: ', accuracy_score(Y_test, clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit your implementation of Logistic Regression on the dataset, predict on test set and compare the results with kmeans approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the coefficients of fitted logistic regression model, drop 2 most unimportant features and train again Logistic regression and Kmeans with best metric, center_init hyperparameters, evaluate and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the coefficients of fitted initial logistic regression model(using all features), select two most important features and train again Logistic regression and Kmeans with best metric, center_init hyperparameters, evaluate and compare results, make the following plot using the test set:\n",
    "\n",
    "datapoints with cluster centers and decision boundary, color the datapoints according to Kmeans predictions\n",
    "color the datapoints on which predictions of logistic regression and Kmeans disagree with separate color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance of best Kmeans model with the performance of Kmeans in sklearn library, using the same hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
